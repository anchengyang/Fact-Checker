{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "### Stanford GloVe, or NLTK "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bag of n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "docs = list(nlp.pipe(df[\"Text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count POS tags per sentence\n",
    "def extract_pos_features(doc):\n",
    "    pos_counts = Counter(token.pos_ for token in doc)\n",
    "    return pos_counts\n",
    "\n",
    "df[\"pos_counts\"] = [extract_pos_features(doc) for doc in docs]\n",
    "\n",
    "# Convert POS tag dictionary into DataFrame\n",
    "pos_df = pd.DataFrame(df[\"pos_counts\"].to_list()).fillna(0)\n",
    "\n",
    "# Merge with original DataFrame\n",
    "df = pd.concat([df, pos_df], axis=1).drop(columns=[\"pos_counts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Verdict</th>\n",
       "      <th>PRON</th>\n",
       "      <th>VERB</th>\n",
       "      <th>AUX</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADP</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I think we've seen a deterioration of values.</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I think for a while as a nation we condoned th...</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>For a while, as I recall, it even seems to me ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>So we've seen a deterioration in values, and o...</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>We got away, we got into this feeling that val...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence_id                                               Text  Verdict  \\\n",
       "0            1      I think we've seen a deterioration of values.       -1   \n",
       "1            2  I think for a while as a nation we condoned th...       -1   \n",
       "2            3  For a while, as I recall, it even seems to me ...       -1   \n",
       "3            4  So we've seen a deterioration in values, and o...       -1   \n",
       "4            5  We got away, we got into this feeling that val...       -1   \n",
       "\n",
       "   PRON  VERB  AUX  DET  NOUN  ADP  PUNCT  SCONJ  ADV  CCONJ  PROPN  ADJ  NUM  \\\n",
       "0   2.0   2.0  1.0  1.0   2.0  1.0    1.0    0.0  0.0    0.0    0.0  0.0  0.0   \n",
       "1   3.0   3.0  2.0  3.0   3.0  2.0    1.0    0.0  0.0    0.0    0.0  0.0  0.0   \n",
       "2   7.0   6.0  1.0  1.0   3.0  3.0    4.0    2.0  1.0    3.0    1.0  2.0  0.0   \n",
       "3   6.0   4.0  3.0  3.0   8.0  7.0    2.0    0.0  1.0    1.0    0.0  1.0  1.0   \n",
       "4   2.0   2.0  1.0  2.0   3.0  2.0    2.0    1.0  1.0    0.0    0.0  1.0  0.0   \n",
       "\n",
       "   PART  INTJ  SYM    X  \n",
       "0   0.0   0.0  0.0  0.0  \n",
       "1   0.0   0.0  0.0  0.0  \n",
       "2   0.0   0.0  0.0  0.0  \n",
       "3   1.0   0.0  0.0  0.0  \n",
       "4   0.0   0.0  0.0  0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lemmas into a single string per sentence\n",
    "df[\"lemmas_str\"] = [\" \".join([token.lemma_ for token in doc]) for doc in docs]\n",
    "\n",
    "# TF-IDF Vectorizer with N-grams\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2, 3), max_features=5000)  # Unigrams, bigrams, trigrams\n",
    "X_tfidf = vectorizer.fit_transform(df[\"lemmas_str\"])\n",
    "\n",
    "# Convert to DataFrame\n",
    "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Merge TF-IDF features with main DataFrame\n",
    "df = pd.concat([df, tfidf_df], axis=1).drop(columns=[\"lemmas_str\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten all POS tags\n",
    "all_pos_tags = [token.pos_ for doc in docs for token in doc]\n",
    "\n",
    "# Encode POS tags\n",
    "le = LabelEncoder()\n",
    "le.fit(all_pos_tags)\n",
    "\n",
    "# Convert each sentence into an array of POS tag integers\n",
    "df[\"pos_encoded\"] = [[le.transform([token.pos_])[0] for token in doc] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save features\n",
    "df.to_csv(\"../data/features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Verdict</th>\n",
       "      <th>PRON</th>\n",
       "      <th>VERB</th>\n",
       "      <th>AUX</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADP</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>...</th>\n",
       "      <th>young woman</th>\n",
       "      <th>young worker</th>\n",
       "      <th>your child</th>\n",
       "      <th>your family</th>\n",
       "      <th>your own</th>\n",
       "      <th>your plan</th>\n",
       "      <th>your question</th>\n",
       "      <th>your taxis</th>\n",
       "      <th>your vote</th>\n",
       "      <th>pos_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I think we've seen a deterioration of values.</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[np.int64(10), np.int64(15), np.int64(10), np....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I think for a while as a nation we condoned th...</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[np.int64(10), np.int64(15), np.int64(1), np.i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>For a while, as I recall, it even seems to me ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[np.int64(1), np.int64(5), np.int64(7), np.int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>So we've seen a deterioration in values, and o...</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[np.int64(2), np.int64(10), np.int64(3), np.in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>We got away, we got into this feeling that val...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[np.int64(10), np.int64(15), np.int64(1), np.i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5021 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence_id                                               Text  Verdict  \\\n",
       "0            1      I think we've seen a deterioration of values.       -1   \n",
       "1            2  I think for a while as a nation we condoned th...       -1   \n",
       "2            3  For a while, as I recall, it even seems to me ...       -1   \n",
       "3            4  So we've seen a deterioration in values, and o...       -1   \n",
       "4            5  We got away, we got into this feeling that val...       -1   \n",
       "\n",
       "   PRON  VERB  AUX  DET  NOUN  ADP  PUNCT  ...  young woman  young worker  \\\n",
       "0   2.0   2.0  1.0  1.0   2.0  1.0    1.0  ...          0.0           0.0   \n",
       "1   3.0   3.0  2.0  3.0   3.0  2.0    1.0  ...          0.0           0.0   \n",
       "2   7.0   6.0  1.0  1.0   3.0  3.0    4.0  ...          0.0           0.0   \n",
       "3   6.0   4.0  3.0  3.0   8.0  7.0    2.0  ...          0.0           0.0   \n",
       "4   2.0   2.0  1.0  2.0   3.0  2.0    2.0  ...          0.0           0.0   \n",
       "\n",
       "   your child  your family  your own  your plan  your question  your taxis  \\\n",
       "0         0.0          0.0       0.0        0.0            0.0         0.0   \n",
       "1         0.0          0.0       0.0        0.0            0.0         0.0   \n",
       "2         0.0          0.0       0.0        0.0            0.0         0.0   \n",
       "3         0.0          0.0       0.0        0.0            0.0         0.0   \n",
       "4         0.0          0.0       0.0        0.0            0.0         0.0   \n",
       "\n",
       "   your vote                                        pos_encoded  \n",
       "0        0.0  [np.int64(10), np.int64(15), np.int64(10), np....  \n",
       "1        0.0  [np.int64(10), np.int64(15), np.int64(1), np.i...  \n",
       "2        0.0  [np.int64(1), np.int64(5), np.int64(7), np.int...  \n",
       "3        0.0  [np.int64(2), np.int64(10), np.int64(3), np.in...  \n",
       "4        0.0  [np.int64(10), np.int64(15), np.int64(1), np.i...  \n",
       "\n",
       "[5 rows x 5021 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select feature columns\n",
    "feature_cols = list(pos_df.columns) + list(tfidf_df.columns) + [\"Verdict\"]  # Combining POS and TF-IDF\n",
    "\n",
    "# X = df[feature_cols]\n",
    "# y = df[\"Verdict\"]\n",
    "\n",
    "features = df[feature_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv('../data/trainable_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# apply the same transformations to test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "test_docs = list(nlp.pipe(test_df[\"Text\"]))\n",
    "\n",
    "# Count POS tags per sentence\n",
    "def extract_pos_features(doc):\n",
    "    pos_counts = Counter(token.pos_ for token in doc)\n",
    "    return pos_counts\n",
    "\n",
    "test_df[\"pos_counts\"] = [extract_pos_features(doc) for doc in test_docs]\n",
    "\n",
    "# Convert POS tag dictionary into DataFrame\n",
    "test_pos_df = pd.DataFrame(test_df[\"pos_counts\"].to_list()).fillna(0)\n",
    "\n",
    "# Merge with original DataFrame\n",
    "test_df = pd.concat([test_df, test_pos_df], axis=1).drop(columns=[\"pos_counts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"lemmas_str\"] = [\" \".join([token.lemma_ for token in doc]) for doc in test_docs]\n",
    "\n",
    "x_test_tfidf = vectorizer.transform(test_df[\"lemmas_str\"])\n",
    "\n",
    "# Convert to DataFrame\n",
    "test_tfidf_df = pd.DataFrame(x_test_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "test_df = pd.concat([test_df, test_tfidf_df], axis=1).drop(columns=[\"lemmas_str\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentence_id', 'Text', 'PRON', 'VERB', 'PUNCT', 'DET', 'NOUN', 'PROPN',\n",
       "       'AUX', 'NUM',\n",
       "       ...\n",
       "       'young people', 'young woman', 'young worker', 'your child',\n",
       "       'your family', 'your own', 'your plan', 'your question', 'your taxis',\n",
       "       'your vote'],\n",
       "      dtype='object', length=5020)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop(columns=[\"Sentence_id\", \"Text\"])\n",
    "\n",
    "X_test.to_csv(\"../data/X_test_features.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
